{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "04b305de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 3 -> CALCULATING THE ACCURACY\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "music_data = pd.read_csv('music.csv')\n",
    "X = music_data.drop(columns=['genre']) # This dont modify the original dataset, just create a new file with the changes\n",
    "y = music_data['genre']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size = 0.2) # arguments are (input, output, size of test dataset)\n",
    "\n",
    "model = DecisionTreeClassifier() # model = new instance of the class. We're allocating 20% of the data for testing\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test) # a male and female predictions at the same time\n",
    "\n",
    "score = accuracy_score(y_test, predictions) # two arguments: the expected values and the predictions which contains the actual values\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d0ad8048",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bebel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['HipHop'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 4 -> PERSISTING MODELS\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import joblib # object that has methods for saving and loading models\n",
    "\n",
    "# music_data = pd.read_csv('music.csv')\n",
    "# X = music_data.drop(columns=['genre']) # This dont modify the original dataset, just create a new file with the changes\n",
    "# y = music_data['genre']\n",
    "\n",
    "# model = DecisionTreeClassifier() # model = new instance of the class. We're allocating 20% of the data for testing\n",
    "# model.fit(X,y)\n",
    "\n",
    "# joblib.dump(model, 'music-recommender.joblib') # save the trained model\n",
    "model = joblib.load('music-recommender.joblib') # load the trained model\n",
    "predictions = model.predict([[21,1]]) # a 21 yeard old female prediction \n",
    "predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "47f1c509",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree # this object has a method for exporting a decision tree in a graphical format\n",
    "\n",
    "music_data = pd.read_csv('music.csv') # dataset\n",
    "X = music_data.drop(columns=['genre']) # input set\n",
    "y = music_data['genre'] # output set\n",
    "\n",
    "model = DecisionTreeClassifier() # model\n",
    "model.fit(X,y) # train it\n",
    "\n",
    "tree.export_graphviz(model, out_file='music-recommender.dot', \n",
    "                      feature_names=['age', 'gender'], # age and gender\n",
    "                      class_names=sorted(y.unique()), # unique list of genres\n",
    "                      label='all', # every node has labels that we can read\n",
    "                      rounded=True, # if node have rounded corners\n",
    "                      filled=True) # if node is filled with a color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86227cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "STEP 1 -> PREPARING THE DATA\n",
    "\n",
    "Separate the dataset in two models input and output\n",
    "input = the necessary data attributes to makes a prediction research or calculate the average\n",
    "output = the result or answer (average/prediction) of the given inputs\n",
    "\n",
    "obs: By convention is used a capital X to represent the input dataset and lower y to represent the output dataset\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7175f52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "STEP 2 -> LEARNING AND PREDICTING\n",
    "\n",
    "Import from the library scikit-learn:\n",
    "* the package: sklearn;\n",
    "* the module: tree;\n",
    "* the class DecisionTreeClassifier (implements the decision tree algorithm)\n",
    "\n",
    "Create a model to train it to it learns patterns in the data.\n",
    "--model = DecisionTreeClassifier()\n",
    "\n",
    "Train it\n",
    "--model.fit(X,y)\n",
    "\n",
    "Ask the model to make a prediction\n",
    "Ex.: What is the kind of music that 21 year old male likes\n",
    "--model.predict([[input],[...]])\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a418f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "STEP 3 -> CALCULATING THE ACCURACY\n",
    "\n",
    "A general rule of thumb is to allocate 70 to 80 percent of our data for training and the other\n",
    "20 to 30 percent for testing.\n",
    "\n",
    "Split the dataset in two sets, for training and testing.\n",
    "--train_test_split() -> This function returns a tuple, so we can unpack it into four variable:\n",
    "X(train/test) and y(train/test)\n",
    "\n",
    "Now for training the model only pass the training dataset\n",
    "--model.fit(X_train,y_train)\n",
    "\n",
    "And when we make prediction pass the input testing dataset\n",
    "model.predictions(X_test)\n",
    "\n",
    "To calculate the accuracy compares the output set for testing (y_test) with the predictions\n",
    "--accuracy_score(y_test, predictions) -> returns a score between 0 to 1\n",
    "\n",
    "obs: Every time we run again then split our dataset into training and test sets we'll have different datasets\n",
    "because this function randomly picks data for training and testing\n",
    "\n",
    "tips: Press ctrl + enter to run the current cell without adding a new cell\n",
    "\n",
    "Key concepts in machine learning\n",
    "\n",
    "Using very little data for training a model worsen the accuracy.\n",
    "The more data we give to our model and the cleaner the data is, we get the better result. Avoid:\n",
    "\n",
    "* duplicates\n",
    "* irrelevants\n",
    "* incomplete\n",
    "\n",
    "That's will learn bad patterns in your data, so it's really important to clean our data before training our model.\n",
    "Also, have enough data. The more complex are problems is the more data we need.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6c773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "STEP 4 -> PERSISTING MODELS\n",
    "\n",
    "In real application we might have a data set with millions or thousands of samples. Traing a model for that maybe takes seconds,\n",
    "minutes, or even hours. So that's why models persistance is important.\n",
    "Once in a while we build and train our model and then we'll save it to a file.\n",
    "\n",
    "Now next time we want to make predictions and we simply load the model from the file and ask it to make predictions. That models\n",
    "is already trained, we dont need to retrain, it's like a intelligent person.\n",
    "\n",
    "First of all, import the joblib.\n",
    "\n",
    "After we train the model, call joblib.\n",
    "joblib.dump(model, 'name-of-file-model')\n",
    "\n",
    "tip: comment all selected lines with ctrl + /\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5522e970",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "STEP 5 -> VIZUALIZING A DECISION TREE\n",
    "\n",
    "Export the model in a visual format so you will see how this model makes predictions.\n",
    "\n",
    "First, import the object tree:\n",
    "-- from sklearn import tree\n",
    "\n",
    "After train the model, call:\n",
    "tree.export_graphiviz(model,out_file='name.dot', \n",
    "                      feature_names=['columns-input', 'columns-input'],\n",
    "                      class_names=sorted(y.unique()),\n",
    "                      label='all',\n",
    "                      rounded=True,\n",
    "                      filled=True)\n",
    "                      \n",
    "-> arguments = model, name of output file, features or columns of the dataset, class or labels in the output dataset like \n",
    "hiphop/dance, label='all', rounded='True', filled=True.\n",
    "\n",
    ".unique() -> returns the unique list of classes, without duplicates.\n",
    "sorted() -> sort the result in alphabetically\n",
    "\n",
    "obs: .dot represents a graph description language\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
